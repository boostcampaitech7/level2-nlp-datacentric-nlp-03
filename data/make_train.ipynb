{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Huggingface 로그인\n",
    "login(\"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\")\n",
    "\n",
    "# 시드 설정 (재현 가능성 보장)\n",
    "SEED = 456\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# 디바이스 설정 (GPU 사용 가능 여부에 따라 선택)\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model_name = \"beomi/Llama-3-Open-Ko-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(DEVICE)\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv('original_train.csv')\n",
    "\n",
    "# 라벨 매핑 정의\n",
    "label_mapping = {\n",
    "    0: '생활문화',\n",
    "    1: '스포츠',\n",
    "    2: '정치',\n",
    "    3: '사회',\n",
    "    4: 'IT과학',\n",
    "    5: '경제',\n",
    "    6: '세계',\n",
    "}\n",
    "\n",
    "# target을 사용해 label 컬럼 생성\n",
    "data['label'] = data['target'].map(label_mapping)\n",
    "\n",
    "# LLaMA 모델의 출력에서 정제된 텍스트 추출\n",
    "def extract_corrected_text(output):\n",
    "    matches = re.findall(r'\"corrected_text\":\\s*\"([^\"]+)\"', output)\n",
    "    return matches[-1] if matches else None\n",
    "\n",
    "# 문장을 주어진 주제에 맞게 수정하는 함수 정의\n",
    "def clean_sentence(noisy_sentence, label):\n",
    "    prompt = f\"\"\"\n",
    "You are required to return the corrected sentence in JSON format. \n",
    "Ensure your response strictly adheres to the JSON structure below.\n",
    "Understand the meaning of the sentence and correctly generate the sentence to fit the topic.\n",
    "Input:\n",
    "Original: \"topic: {label}, sentence: {noisy_sentence}\"\n",
    "Output:\n",
    "{{\n",
    "    \"corrected_text\": \"<corrected sentence>\"\n",
    "}}\n",
    "\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to(DEVICE)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=128, pad_token_id=tokenizer.eos_token_id)\n",
    "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    corrected_sentence = extract_corrected_text(decoded_output)\n",
    "    return corrected_sentence if corrected_sentence else noisy_sentence\n",
    "\n",
    "# tqdm을 사용해 진행 상황 출력\n",
    "tqdm.pandas()\n",
    "\n",
    "# 필요 없는 'label' 열 삭제\n",
    "data = data.drop(columns=['label'])\n",
    "\n",
    "# 최종 데이터 저장\n",
    "data.to_csv('train_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
